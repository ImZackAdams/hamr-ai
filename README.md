# HAMR  
**Hierarchical Adaptive Memory Retrieval**  
for LLMs that arenâ€™t goldfish ðŸ§ ðŸ”¥

---

## ðŸš€ TL;DR  
LLMs are sharp... for like 4K tokens. Then they forget everything.  
Context limits kill long chats. Current RAG? Static, dumb, bloated.  
**HAMR** is layered memoryâ€”short, mid, long-termâ€”ranked by relevance, recency, and importance.  
We build the prompt on the fly. No filler. No forgetting. Just results.

---

## ðŸ¤® The Problem  
LLMs can't remember anything past the current prompt. Youâ€™ve got two bad options:

- **Keep it all** â†’ bloated prompt, wasted tokens  
- **Trim it down** â†’ lose the plot

RAG helps, kinda...  
But it's a glorified chunk retriever. No memory, no prioritization, no structure. Just "semantic similarity" and vibes.

---

## ðŸ”¨ The HAMR Fix

### ðŸ§± Layered Memory Stores  
1. **Short-Term**  
   - Raw recent chat turns  
   - Just text, no processing  

2. **Mid-Term**  
   - Event-based summaries  
   - Triggered on intent shifts, decisions, milestones  

3. **Long-Term**  
   - Abstracted topics  
   - Knowledge graphs, clusters, core facts  

---

### âš¡ Runtime Query Flow  
Every query triggers:  
- **Embedding** of the new question  
- **Scoring** all memory chunks on:
  - Semantic relevance
  - Recency (decay over time)
  - Importance (custom/manual/learned)
- **Filtering** to fit token budget  
- **Prompt Assembly** in priority order  
  - Recent beats old  
  - Raw beats summarized  
  - Junk gets dropped

---

## ðŸ“ˆ Why This Matters  
LLMs without memory are toys.  
You want real assistants? Real narratives? Real tools?

You need memory.

### ðŸ“Š Metrics We Care About  
- **Recall Accuracy**: remembers critical info over time  
- **Token Efficiency**: tokens per useful detail  
- **Coherence**: does it all make sense?  
- **Latency**: is it fast enough to ship?

---

## ðŸ§  Use Cases  
- Multi-day customer support that doesnâ€™t lose your thread  
- Enterprise tools that know more than a PDF  
- Story agents that evolve like D&D, not goldfish

---

## âš ï¸ What Still Sucks  
- Summaries might hallucinate  
- Big topic shifts can confuse the retrieval  
- Summarization/indexing adds compute overhead

But none of thatâ€™s fatal. Itâ€™s just engineering.

---

## ðŸ› ï¸ Next Steps

### 0. Prototype It  
- Manual layered store  
- FAISS / Chroma / whatever  
- Hacky prompt builder

### 1. Benchmark  
- Long-context eval sets  
- New evals for memory coherence

### 2. Open Source  
- Clean repo  
- Plug-and-play with open LLMs  
- Memory inspector / override tools

### 3. Stretch Goals  
- Multi-agent memory sync  
- Streaming input support  
- User curation & privacy tools

---

## ðŸ™‹â€â™‚ï¸ Why Bother?  
Because stateless transformers suck at memory.  
This isnâ€™t AGI. This is just **cache + search + relevance scoring**.

LLMs are compressed intelligence.  
**HAMR is compressed memory.**

Letâ€™s build it.

---

> Made by people who hate forgetting stuff.  
> PRs welcome.  
